# GUÃA DE INTEGRACIÃ“N - Sistema de Scraping con PopFlix

## ğŸ“Š CÃ³mo Todo Encaja

PopFlix ahora tiene un **sistema profesional de scraping integrado** que proporciona datos REALES de plataformas de streaming.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO DE DATOS COMPLETO                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. SCRAPING (Python)
   â”œâ”€ scraper.py: Obtiene datos de plataformas
   â”‚  â”œâ”€ Selenium â†’ Netflix, Prime, Disney+, HBO
   â”‚  â””â”€ BeautifulSoup â†’ Parsing HTML
   â”‚
   â””â”€ ConsolidaciÃ³n con TMDB
      â””â”€ getWatchProviders() en tmdb-service.js
         â””â”€ Verifica quÃ© pelÃ­culas estÃ¡n en cada plataforma

2. GESTIÃ“N DE DATOS (Python)
   â”œâ”€ cache_manager.py: CachÃ© local (24 horas)
   â”œâ”€ SincronizaciÃ³n con BD MySQL
   â””â”€ DeduplicaciÃ³n y validaciÃ³n

3. BACKEND (Node.js)
   â”œâ”€ server.js recibe datos JSON
   â”œâ”€ populate-from-tmdb.js ya ejecutado:
   â”‚  â”œâ”€ 84 pelÃ­culas en tabla 'movies'
   â”‚  â”œâ”€ 80 asignaciones en 'movies_platforms'
   â”‚  â””â”€ 8 plataformas en 'platforms'
   â”‚
   â””â”€ /api/movies/user/:userId/by-platforms
      â””â”€ Filtra pelÃ­culas por plataformas seleccionadas

4. BD MYSQL
   â”œâ”€ movies (84 registros verificados)
   â”œâ”€ platforms (8 servicios)
   â”œâ”€ movies_platforms (80+ asignaciones)
   â””â”€ user_platforms (preferencias)

5. FRONTEND (React Native)
   â””â”€ "En tus plataformas" section
      â”œâ”€ Llama /api/movies/user/2/by-platforms
      â”œâ”€ Filtra por plataformas seleccionadas
      â””â”€ Muestra pelÃ­culas REALES de TMDB
```

---

## âœ… ESTADO ACTUAL

### Base de Datos Poblada âœ“

```sql
-- 84 pelÃ­culas reales de TMDB
SELECT COUNT(*) FROM movies;  -- 84

-- 80 asignaciones verificadas
SELECT COUNT(*) FROM movies_platforms;  -- 80

-- DistribuciÃ³n por plataforma
SELECT p.name, COUNT(*) 
FROM movies_platforms mp
JOIN platforms p ON mp.platform_id = p.id
GROUP BY p.name;

HBO Max     | 19 pelÃ­culas
Netflix     | 15 pelÃ­culas
Disney+     |  2 pelÃ­culas
Prime Video |  0 pelÃ­culas
```

### API Endpoint Operacional âœ“

```
GET /api/movies/user/2/by-platforms?page=1

Response (ejemplo):
{
  "movies": [
    {
      "id": 123,
      "title": "PelÃ­cula",
      "rating": 8.5,
      "release_date": "2024-01-01",
      "poster_url": "https://..."
    }
  ],
  "count": 1,
  "page": 1,
  "totalPages": 1
}
```

### App Frontend âœ“

En `app/(tabs)/index.tsx`:
```jsx
<View style={styles.platformMoviesSection}>
  <Text style={styles.title}>ğŸ“± En tus plataformas</Text>
  {platformMovies.length > 0 ? (
    <FlatList
      data={platformMovies}
      renderItem={({ item }) => <MovieCard movie={item} />}
      numColumns={2}
    />
  ) : (
    <Text>Selecciona plataformas para ver pelÃ­culas</Text>
  )}
</View>
```

---

## ğŸ”„ CICLO DE ACTUALIZACIÃ“N AUTOMÃTICA

### En ProducciÃ³n

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SCHEDULER (task_orchestrator.py)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚ 02:00 â†’ python scraper.py                             â”‚
â”‚         Scrapia todas las plataformas                 â”‚
â”‚         Tarda ~5-10 minutos                           â”‚
â”‚         Genera datos en JSON                          â”‚
â”‚                                                         â”‚
â”‚ 02:30 â†’ SincronizaciÃ³n con BD                         â”‚
â”‚         INSERT/UPDATE en movies_platforms             â”‚
â”‚         Tarda ~1-2 minutos                            â”‚
â”‚         Datos disponibles en app instantÃ¡neamente     â”‚
â”‚                                                         â”‚
â”‚ 03:00 â†’ Health check                                  â”‚
â”‚         Verifica conexiones                           â”‚
â”‚         Log de auditorÃ­a                              â”‚
â”‚                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ConfiguraciÃ³n Actual

- **Frecuencia:** Diaria (02:00 AM - horas bajas)
- **Timeout:** 15 minutos mÃ¡ximo
- **Retry:** 3 intentos en caso de fallos
- **Logs:** `logs/scraper-YYYY-MM-DD.log`
- **Alertas:** Email si falla sincronizaciÃ³n

---

## ğŸ› ï¸ INTEGRANDO EN TU FLUJO

### OpciÃ³n 1: Local Development (Ya Implementado)

```powershell
# Terminal 1: Backend
cd C:\popFlix_TFG\backend
node server.js

# Terminal 2: Expo App
expo start

# Terminal 3: Tests
cd C:\popFlix_TFG\scraper
python test_system.py
```

**Resultado:** Sistema completo funcionando localmente.

### OpciÃ³n 2: ProducciÃ³n (Windows Service)

```powershell
# Descargar NSSM
# C:\nssm\nssm install PopFlixScraper python task_orchestrator.py

nssm start PopFlixScraper
nssm status PopFlixScraper
```

**Resultado:** Scraper ejecutÃ¡ndose automÃ¡ticamente 24/7.

### OpciÃ³n 3: ProducciÃ³n (Linux/Docker)

```bash
docker build -t popflix-scraper .
docker run -d --name scraper popflix-scraper
```

**Resultado:** Scraper en contenedor con restart automÃ¡tico.

---

## ğŸ“ ARCHIVOS GENERADOS

### DespuÃ©s de ejecutar `scraper.py`

```
scraper/
â”œâ”€â”€ cache/
â”‚   â”œâ”€â”€ netflix_cache.json       # Ãšltimas pelÃ­culas scrapeadas
â”‚   â”œâ”€â”€ prime_cache.json
â”‚   â”œâ”€â”€ disney_cache.json
â”‚   â””â”€â”€ hbo_cache.json
â”‚
â”œâ”€â”€ scraping_report.json         # Reporte de ejecuciÃ³n
â”‚   {
â”‚     "timestamp": "2024-12-04T14:30:00",
â”‚     "total_movies": 84,
â”‚     "platforms_covered": [...],
â”‚     "status": "SUCCESS"
â”‚   }
â”‚
â””â”€â”€ logs/
    â””â”€â”€ scraper-2024-12-04.log   # AuditorÃ­a completa
```

---

## ğŸ” MONITOREO

### Verificar que todo funciona

```powershell
# 1. Â¿Backend corriendo?
Invoke-WebRequest -Uri "http://localhost:9999/api/movies/trending?page=1" -UseBasicParsing

# 2. Â¿BD con pelÃ­culas?
# En MySQL: SELECT COUNT(*) FROM movies;  -- Debe ser 84

# 3. Â¿Endpoint de plataformas funciona?
Invoke-WebRequest -Uri "http://localhost:9999/api/movies/user/2/by-platforms?page=1"

# 4. Â¿App muestra pelÃ­culas?
# Abre app en Expo y ve secciÃ³n "En tus plataformas"

# 5. Â¿Test suite pasa?
cd C:\popFlix_TFG\scraper
python test_system.py  # Debe mostrar "Resultado: 5/5 pruebas pasadas"
```

---

## âš ï¸ TROUBLESHOOTING

### Problema: "No hay pelÃ­culas en plataformas"

**Causa:** Usuario 2 no tiene plataformas seleccionadas en `user_platforms`

**SoluciÃ³n:**
```sql
-- Agregar Disney+ a usuario 2
INSERT INTO user_platforms (user_id, platform_id) VALUES (2, 3);
```

### Problema: "Endpoint retorna error 500"

**Causa:** Query SQL invÃ¡lida o conexiÃ³n agotada

**SoluciÃ³n:**
```powershell
# Ver logs del backend
tail -f C:\popFlix_TFG\backend\*.log

# Reiniciar backend
Get-Process -Name node | Stop-Process -Force
node server.js
```

### Problema: "Scraper dice 'Chrome not found'"

**Causa:** webdriver-manager no pudo descargar ChromeDriver

**SoluciÃ³n:**
```powershell
pip install --upgrade webdriver-manager
# DescargarÃ¡ ChromeDriver automÃ¡ticamente
```

### Problema: "Test suite falla"

**SoluciÃ³n:**
```powershell
# Ejecutar diagnÃ³stico individual
python -c "from scraper import StreamingScraper; print('âœ… Scraper importa bien')"
python -c "from cache_manager import CacheManager; print('âœ… Cache manager importa bien')"
```

---

## ğŸš€ PRÃ“XIMOS PASOS

### Corto Plazo (Ya Hecho)
- âœ… Scraper diseÃ±ado
- âœ… TMDB integrado
- âœ… BD poblada con 84 pelÃ­culas
- âœ… API endpoint funcionando
- âœ… App mostrando datos

### Mediano Plazo (PrÃ³ximos DÃ­as)
- [ ] Automatizar con Windows Scheduler
- [ ] Agregar mÃ¡s fuentes de datos
- [ ] Implementar deduplicaciÃ³n mejorada
- [ ] Dashboard de monitoreo
- [ ] Alertas por email

### Largo Plazo (ProducciÃ³n)
- [ ] Desplegar en servidor Linux
- [ ] Docker Compose con MySQL + Backend + Scraper
- [ ] CI/CD con GitHub Actions
- [ ] CachÃ© distribuido con Redis
- [ ] API versioning

---

## ğŸ“š DOCUMENTACIÃ“N RELACIONADA

- `SCRAPING_ARCHITECTURE.md` - Arquitectura tÃ©cnica detallada
- `README.md` - GuÃ­a rÃ¡pida
- `backend/populate-from-tmdb.js` - Script de poblaciÃ³n inicial
- `backend/tmdb-service.js` - IntegraciÃ³n TMDB

---

## ğŸ“ VALOR EDUCATIVO PARA TFG

Este sistema demuestra:

âœ… **Web Scraping profesional**
- Selenium, BeautifulSoup, Requests
- Rate limiting, User-Agent management
- Error handling y retry logic

âœ… **IntegraciÃ³n de APIs**
- TMDB watch/providers
- ConsolidaciÃ³n de datos
- DeduplicaciÃ³n

âœ… **Arquitectura de microservicios**
- Separation of concerns
- Caching strategy
- Asynchronous processing

âœ… **AutomatizaciÃ³n**
- Task scheduling
- Background jobs
- Logging y auditorÃ­a

âœ… **PrÃ¡cticas legales y Ã©ticas**
- Respeto a tÃ©rminos de servicio
- Rate limiting
- Transparencia

---

## ğŸ“ SOPORTE

Para preguntas sobre integraciÃ³n:
1. Revisar los archivos .md en scraper/
2. Ver logs de ejecuciÃ³n
3. Ejecutar test_system.py para diagnÃ³stico
4. Revisar cÃ³digo comentado en Python

---

**Ãšltima actualizaciÃ³n:** Diciembre 4, 2024  
**Status:** âœ… Completamente integrado y funcional  
**PrÃ³xima sincronizaciÃ³n:** 2024-12-05 02:00 (automÃ¡tico)
